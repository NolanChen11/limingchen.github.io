<!DOCTYPE html>
<html lang="en">

<head>
    <script src="./p5.min.js"></script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" type="text/css" href="styles.css" />
    <title>Liming Chen</title>
</head>

<body>
    <header>
        <a href="index.html">
            <div class="secondLogoWrapper">
                <img class="secondLogo" src="./images/logo.PNG">
            </div>

        </a>
    </header>
    <hr>
    <section class="projectName">
        <h1>
            Individual Project: Machine-Learned Nature
        </h1>

    </section>


    <section class="gallery">

        <p class="text">
            Machine-Learned Nature is an on-going project that aims to use machine learning models as a medium of
            information, converting one's surrounding nature into an artistic and digital representation.
            <br>
            <br>
            Rather than training the model on large datasets, using customized datasets might provide models that
            are more relevant to individuals. Thus, developing a workflow that allows one to easily collect data and
            train the model is an important topic of this project.
            <br>
            <br>
            For the installation I created for my Studio Art capstone project, I trained a pix2pix translation model
            using <a href = "https://phillipi.github.io/pix2pix/">a conditional GAN framework by Phillip Isola Et al</a>. The training sets were processed from the pictures of nature I took around my living place.
            <br>
            <br>

        </p>
        <img src="images/cover_machine_learned_nature.png" alt="" style=" max-width: 60%;
        width:60%;
        height:auto;
        text-align: center;
        vertical-align: center;
        display:inline-flex;">
        <p class="text">

            <br>
            <br>
            To increase the number of instances, I divided the images into uniform smaller segments. Subsequently,
            employing morphological transformations and edge detection techniques, I generated processed images
            (labels) and retained the original cropped images as attributes within my dataset. Here are some examples of the training data.
            <br>
            <br>
        </p>
        <br>
        <img src="images/machine_learned_nature_dataIllustration.png" alt="part of my datasets" class = "inTextImageSmall">

        <br>
        <br>
        <p class="text">
            The trained model can translate the black and white input to colorful "nature style". Thus, I programed
            some moving patterns in Processing, which represents the instances in my dataset --- stones, clouds,
            grass, branches. Then, I input the patterns to the model to get the final outcomes.
        </p>
        <br>
        <br>
        <img src="images/machine_learned_nature_results.png" alt="" class="inTextImageSmall">
        <br>
        <br>

    </section>



    <br>
    <br>



</body>

</html>