<!DOCTYPE html>
<html lang="en">

<head>
    <script src="./p5.min.js"></script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" type="text/css" href="styles.css" />
    <title>Liming Chen</title>
</head>

<body>
    <header>
        <a href="index.html">
            <div class="secondLogoWrapper">
                <img class="secondLogo" src="./images/logo.PNG">
            </div>

        </a>
    </header>
    <hr>
    <section class="projectName">
        <h1>
            Video Frame Interpolation and Super-Resolution Using Conditional GAN and Autoencoders.
        </h1>
        <p>
            -Liming Chen, Benjamin Rapkin, Xuhang Cao.
        </p>
    </section>


    <section class="gallery">

        <p class="text">
            Video frame interpolation is a technique that increases the quality of a video by adding a new frame between
            two existing adjacent frames. In our work, we constructed a conditional generative adversarial network
            (CGAN) to
            train our model using PyTorch and trained an Autoencoder using
            TensorFlow, and I was responsible for training GANs and their training framework. 
            <br>
            <br>
            Our customized data loader class reads three sequential frames in the video as one instance,
            f(n-1), f(n) and f(n+1), while all of the 3 frames are numpy arrays with a shape of width, height, RGB
            values (256 * 256 * 3). Our data loader transforms f(n) to a (3 * 256 *256) tensor as the label. Then, It
            combines and transforms f(n-1) and f(n+1) to a (6 * 256 * 256) tensor as the attributes.
            <br>
            <br>
            Our DCGAN consists of 2 convolutional networksâ€”a generative neural network(generator) and a discriminative
            neural network(discriminator). The generator takes the combined (6 * 256 * 256) tensor of f(n-1) and f(n+1)
            as the
            input and generates a fake intermediate frame f(p) between f(n-1) and f(n+1). The discriminator is trained
            to distinguish whether its input image is the real intermediate frame or the fake frame generated by the
            generator, using a binary prediction - '0' for fake and '1' for real.
            <br>
            <br>
            For every 30 epochs, Our program automatically saves the parameters in the generator using the state_dict
            function in PyTorch's neural network module. Then, to apply our trained generator to generate the new
            intermediate frames between every pair of existing frames, we loaded the saved generator parameters. By inputting
            combined (6 * 256 * 256) tensors of f(n) and f(n+1), the generator can predict the intermediate frames
            between f(n) and f(n+1).
            <br>
            <br>
            The result was not ideal, while the model successfully predicted the general features of intermediate frames.



        </p>
        <img src="images/videoFrameInterpolation.png" alt="" class="inTextImage">
        


    </section>



    <br>
    <br>



</body>

</html>